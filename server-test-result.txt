================================================
  remote-ollama ai-server Test Suite
  Running 26 tests
================================================

=== Service Status Tests ===
[0;34m[Test 1/26][0m Checking if LaunchAgent is loaded...
[0;32mâœ“ PASS[0m LaunchAgent com.ollama is loaded
[0;34m[Test 2/26][0m Checking Ollama process owner...
[0;32mâœ“ PASS[0m Ollama process running as user: vm (PID: 19256)
[0;34m[Test 3/26][0m Checking if port 11434 is listening...
[0;32mâœ“ PASS[0m Service listening on port 11434
[0;34m[Test 4/26][0m Testing basic HTTP response...
[0;32mâœ“ PASS[0m Service responds to HTTP requests

=== API Endpoint Tests ===
[0;34m[Test 5/26][0m Testing GET /v1/models...
[0;32mâœ“ PASS[0m GET /v1/models returns valid JSON (1 models)
[0;34m[INFO][0m First available model: qwen2.5:0.5b
[0;34m[Test 6/26][0m Testing GET /v1/models/qwen2.5:0.5b...
[0;32mâœ“ PASS[0m GET /v1/models/{model} returns valid model details
[0;34m[Test 7/26][0m Testing POST /v1/chat/completions (non-streaming) with model: qwen2.5:0.5b...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/chat/completions
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","messages":[{"role":"user","content":"hi"}],"max_tokens":1}
[0;34m[INFO][0m Response:
[0;34m[INFO][0m     0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying [::1]:11434...
[0;34m[INFO][0m   * Connected to localhost (::1) port 11434
[0;34m[INFO][0m   > POST /v1/chat/completions HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > Content-Length: 83
[0;34m[INFO][0m   > 
[0;34m[INFO][0m   } [83 bytes data]
[0;34m[INFO][0m   * upload completely sent off: 83 bytes
[0;34m[INFO][0m   100    83    0     0  100    83      0    402 --:--:-- --:--:-- --:--:--   400< HTTP/1.1 200 OK
[0;34m[INFO][0m   < Content-Type: application/json
[0;34m[INFO][0m   < Date: Wed, 11 Feb 2026 00:03:56 GMT
[0;34m[INFO][0m   < Content-Length: 293
[0;34m[INFO][0m   < 
[0;34m[INFO][0m   { [293 bytes data]
[0;34m[INFO][0m   100   376  100   293  100    83    832    235 --:--:-- --:--:-- --:--:--  1068
[0;34m[INFO][0m   * Connection #0 to host localhost left intact
[0;34m[INFO][0m   {"id":"chatcmpl-616","object":"chat.completion","created":1770768236,"model":"qwen2.5:0.5b","system_fingerprint":"fp_ollama","choices":[{"index":0,"message":{"role":"assistant","content":"Hello"},"finish_reason":"length"}],"usage":{"prompt_tokens":30,"completion_tokens":1,"total_tokens":31}}
[0;34m[INFO][0m Elapsed time: 369523000000ms
[0;31mâœ— FAIL[0m POST /v1/chat/completions (non-streaming) failed
[0;34m[Test 8/26][0m Testing POST /v1/chat/completions (streaming)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/chat/completions (streaming)
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","messages":[{"role":"user","content":"hi"}],"max_tokens":1,"stream":true}
[0;34m[INFO][0m Response (first 10 lines):
[0;34m[INFO][0m   * Host localhost:11434 was resolved.
[0;34m[INFO][0m   * IPv6: ::1
[0;34m[INFO][0m   * IPv4: 127.0.0.1
[0;34m[INFO][0m     % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[0;34m[INFO][0m                                    Dload  Upload   Total   Spent    Left  Speed
[0;34m[INFO][0m     0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying [::1]:11434...
[0;34m[INFO][0m   * Connected to localhost (::1) port 11434
[0;34m[INFO][0m   > POST /v1/chat/completions HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m Elapsed time: 194951000000ms
[0;32mâœ“ PASS[0m POST /v1/chat/completions (streaming) returns SSE chunks
[0;34m[Test 9/26][0m Testing POST /v1/chat/completions (stream_options.include_usage)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/chat/completions (streaming with include_usage)
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","messages":[{"role":"user","content":"hi"}],"max_tokens":1,"stream":true,"stream_options":{"include_usage":true}}
[0;34m[INFO][0m Response (all SSE chunks):
[0;34m[INFO][0m   data: {"id":"chatcmpl-276","object":"chat.completion.chunk","created":1770768236,"model":"qwen2.5:0.5b","system_fingerprint":"fp_ollama","choices":[{"index":0,"delta":{"role":"assistant","content":"Hello"},"finish_reason":null}]}
[0;34m[INFO][0m   data: {"id":"chatcmpl-276","object":"chat.completion.chunk","created":1770768236,"model":"qwen2.5:0.5b","system_fingerprint":"fp_ollama","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":"length"}]}
[0;34m[INFO][0m   data: {"id":"chatcmpl-276","object":"chat.completion.chunk","created":1770768236,"model":"qwen2.5:0.5b","system_fingerprint":"fp_ollama","choices":[],"usage":{"prompt_tokens":30,"completion_tokens":1,"total_tokens":31}}
[0;34m[INFO][0m   data: [DONE]
[0;34m[INFO][0m Elapsed time: 195624000000ms
[0;32mâœ“ PASS[0m POST /v1/chat/completions (stream_options.include_usage) succeeded (usage field found)
[0;34m[Test 10/26][0m Testing POST /v1/chat/completions (JSON mode)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/chat/completions (JSON mode)
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","messages":[{"role":"user","content":"Return a JSON object with a single field 'status' set to 'ok'"}],"max_tokens":20,"response_format":{"type":"json_object"}}
[0;34m[INFO][0m Response:
[0;34m[INFO][0m     0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying [::1]:11434...
[0;34m[INFO][0m   * Connected to localhost (::1) port 11434
[0;34m[INFO][0m   > POST /v1/chat/completions HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > Content-Length: 184
[0;34m[INFO][0m   > 
[0;34m[INFO][0m   } [184 bytes data]
[0;34m[INFO][0m   * upload completely sent off: 184 bytes
[0;34m[INFO][0m   100   184    0     0  100   184      0    152  0:00:01  0:00:01 --:--:--   152< HTTP/1.1 200 OK
[0;34m[INFO][0m   < Content-Type: application/json
[0;34m[INFO][0m   < Date: Wed, 11 Feb 2026 00:03:58 GMT
[0;34m[INFO][0m   < Content-Length: 313
[0;34m[INFO][0m   < 
[0;34m[INFO][0m   { [313 bytes data]
[0;34m[INFO][0m   100   497  100   313  100   184    184    108  0:00:01  0:00:01 --:--:--   292100   497  100   313  100   184    184    108  0:00:01  0:00:01 --:--:--   292
[0;34m[INFO][0m   * Connection #0 to host localhost left intact
[0;34m[INFO][0m   {"id":"chatcmpl-380","object":"chat.completion","created":1770768238,"model":"qwen2.5:0.5b","system_fingerprint":"fp_ollama","choices":[{"index":0,"message":{"role":"assistant","content":"{
  \"status\": \"ok\"
}"},"finish_reason":"stop"}],"usage":{"prompt_tokens":45,"completion_tokens":10,"total_tokens":55}}
[0;34m[INFO][0m Elapsed time: 1713920000000ms
[0;31mâœ— FAIL[0m POST /v1/chat/completions (JSON mode) failed
[0;34m[Test 11/26][0m Testing POST /v1/responses (experimental)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/responses (experimental)
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","messages":[{"role":"user","content":"hi"}],"max_tokens":1}
[0;34m[INFO][0m Response:
[0;34m[INFO][0m     0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying [::1]:11434...
[0;34m[INFO][0m   * Connected to localhost (::1) port 11434
[0;34m[INFO][0m   > POST /v1/responses HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > Content-Length: 83
[0;34m[INFO][0m   > 
[0;34m[INFO][0m   } [83 bytes data]
[0;34m[INFO][0m   * upload completely sent off: 83 bytes
[0;34m[INFO][0m   < HTTP/1.1 200 OK
[0;34m[INFO][0m   < Content-Type: application/json
[0;34m[INFO][0m   < Date: Wed, 11 Feb 2026 00:03:58 GMT
[0;34m[INFO][0m   < Content-Length: 926
[0;34m[INFO][0m   < 
[0;34m[INFO][0m   { [926 bytes data]
[0;34m[INFO][0m   100  1009  100   926  100    83  15741   1410 --:--:-- --:--:-- --:--:-- 17396
[0;34m[INFO][0m   * Connection #0 to host localhost left intact
[0;34m[INFO][0m   {"id":"resp_597723","object":"response","created_at":1770768238,"completed_at":1770768238,"status":"completed","incomplete_details":null,"model":"qwen2.5:0.5b","previous_response_id":null,"instructions":null,"output":[{"id":"msg_139089","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"","annotations":[],"logprobs":[]}]}],"error":null,"tools":[],"tool_choice":"auto","truncation":"disabled","parallel_tool_calls":true,"text":{"format":{"type":"text"}},"top_p":1,"presence_penalty":0,"frequency_penalty":0,"top_logprobs":0,"temperature":1,"reasoning":null,"usage":{"input_tokens":0,"output_tokens":0,"total_tokens":0,"input_tokens_details":{"cached_tokens":0},"output_tokens_details":{"reasoning_tokens":0}},"max_output_tokens":null,"max_tool_calls":null,"store":false,"background":false,"service_tier":"default","metadata":{},"safety_identifier":null,"prompt_cache_key":null}
[0;34m[INFO][0m Elapsed time: 79274000000ms
[1;33mâŠ˜ SKIP[0m POST /v1/responses - endpoint exists but returned non-JSON (may not be supported)
  [0;34mTo enable:[0m Upgrade to Ollama 0.5.0+

=== Anthropic API Tests ===
[0;34m[Test 12/26][0m Testing POST /v1/messages (non-streaming)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/messages
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","max_tokens":10,"messages":[{"role":"user","content":"Hello"}]}
[0;34m[INFO][0m Response:
[0;34m[INFO][0m   > POST /v1/messages HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > x-api-key: ollama
[0;34m[INFO][0m   > anthropic-version: 2023-06-01
[0;34m[INFO][0m   > Content-Length: 87
[0;34m[INFO][0m   > 
[0;34m[INFO][0m   } [87 bytes data]
[0;34m[INFO][0m   * upload completely sent off: 87 bytes
[0;34m[INFO][0m   100    87    0     0  100    87      0     71  0:00:01  0:00:01 --:--:--    71< HTTP/1.1 200 OK
[0;34m[INFO][0m   < Content-Type: application/json
[0;34m[INFO][0m   < Date: Wed, 11 Feb 2026 00:03:59 GMT
[0;34m[INFO][0m   < Content-Length: 241
[0;34m[INFO][0m   < 
[0;34m[INFO][0m   { [241 bytes data]
[0;34m[INFO][0m   100   328  100   241  100    87    189     68  0:00:01  0:00:01 --:--:--   257
[0;34m[INFO][0m   * Connection #0 to host localhost left intact
[0;34m[INFO][0m   {"id":"msg_7bea9cc9c6f1f6a57c3f36e7","type":"message","role":"assistant","model":"qwen2.5:0.5b","content":[{"type":"text","text":"Hello! How can I assist you today?"}],"stop_reason":"end_turn","usage":{"input_tokens":30,"output_tokens":10}}
[0;34m[INFO][0m Elapsed time: 1290586000000ms
[1;33mâŠ˜ SKIP[0m POST /v1/messages (non-streaming) - endpoint not available
  [0;34mTo enable:[0m Upgrade to Ollama 0.5.0+
[0;34m[Test 13/26][0m Testing POST /v1/messages (streaming SSE)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/messages (streaming)
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","max_tokens":10,"messages":[{"role":"user","content":"Hello"}],"stream":true}
[0;34m[INFO][0m Response (first 15 lines):
[0;34m[INFO][0m   * Host localhost:11434 was resolved.
[0;34m[INFO][0m   * IPv6: ::1
[0;34m[INFO][0m   * IPv4: 127.0.0.1
[0;34m[INFO][0m     % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[0;34m[INFO][0m                                    Dload  Upload   Total   Spent    Left  Speed
[0;34m[INFO][0m     0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying [::1]:11434...
[0;34m[INFO][0m   * Connected to localhost (::1) port 11434
[0;34m[INFO][0m   > POST /v1/messages HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > x-api-key: ollama
[0;34m[INFO][0m   > anthropic-version: 2023-06-01
[0;34m[INFO][0m   > Content-Length: 101
[0;34m[INFO][0m Elapsed time: 1270316000000ms
[0;32mâœ“ PASS[0m POST /v1/messages (streaming SSE) returns Anthropic SSE events
[0;34m[Test 14/26][0m Testing POST /v1/messages (system prompt)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/messages (with system prompt)
[0;34m[INFO][0m Body: {"model":"qwen2.5:0.5b","max_tokens":10,"system":"You are helpful.","messages":[{"role":"user","content":"Hi"}]}
[0;34m[INFO][0m Response:
[0;34m[INFO][0m   > POST /v1/messages HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > x-api-key: ollama
[0;34m[INFO][0m   > anthropic-version: 2023-06-01
[0;34m[INFO][0m   > Content-Length: 112
[0;34m[INFO][0m   > 
[0;34m[INFO][0m   } [112 bytes data]
[0;34m[INFO][0m   * upload completely sent off: 112 bytes
[0;34m[INFO][0m   100   112    0     0  100   112      0     92  0:00:01  0:00:01 --:--:--    92< HTTP/1.1 200 OK
[0;34m[INFO][0m   < Content-Type: application/json
[0;34m[INFO][0m   < Date: Wed, 11 Feb 2026 00:04:02 GMT
[0;34m[INFO][0m   < Content-Length: 239
[0;34m[INFO][0m   < 
[0;34m[INFO][0m   { [239 bytes data]
[0;34m[INFO][0m   100   351  100   239  100   112    168     78  0:00:01  0:00:01 --:--:--   246
[0;34m[INFO][0m   * Connection #0 to host localhost left intact
[0;34m[INFO][0m   {"id":"msg_1ce8eb26ee1608362b4f0d2f","type":"message","role":"assistant","model":"qwen2.5:0.5b","content":[{"type":"text","text":"Hello! How can I help you today?"}],"stop_reason":"end_turn","usage":{"input_tokens":18,"output_tokens":10}}
[0;34m[INFO][0m Elapsed time: 1436344000000ms
[1;33mâŠ˜ SKIP[0m POST /v1/messages (system prompt) - endpoint not available
  [0;34mTo enable:[0m Upgrade to Ollama 0.5.0+
[0;34m[Test 15/26][0m Testing POST /v1/messages error handling...
[0;32mâœ“ PASS[0m POST /v1/messages error handling returns error status (404)
[0;34m[Test 16/26][0m Testing POST /v1/messages (multi-turn conversation)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/messages (multi-turn)
[0;34m[INFO][0m Body: Multi-turn conversation with 3 messages
[0;34m[INFO][0m Response:
[0;34m[INFO][0m   > POST /v1/messages HTTP/1.1
[0;34m[INFO][0m   > Host: localhost:11434
[0;34m[INFO][0m   > User-Agent: curl/8.7.1
[0;34m[INFO][0m   > Accept: */*
[0;34m[INFO][0m   > Content-Type: application/json
[0;34m[INFO][0m   > x-api-key: ollama
[0;34m[INFO][0m   > anthropic-version: 2023-06-01
[0;34m[INFO][0m   > Content-Length: 268
[0;34m[INFO][0m   > 
[0;34m[INFO][0m   } [268 bytes data]
[0;34m[INFO][0m   * upload completely sent off: 268 bytes
[0;34m[INFO][0m   < HTTP/1.1 200 OK
[0;34m[INFO][0m   < Content-Type: application/json
[0;34m[INFO][0m   < Date: Wed, 11 Feb 2026 00:04:03 GMT
[0;34m[INFO][0m   < Content-Length: 224
[0;34m[INFO][0m   < 
[0;34m[INFO][0m   { [224 bytes data]
[0;34m[INFO][0m   100   492  100   224  100   268    279    334 --:--:-- --:--:-- --:--:--   614100   492  100   224  100   268    279    334 --:--:-- --:--:-- --:--:--   614
[0;34m[INFO][0m   * Connection #0 to host localhost left intact
[0;34m[INFO][0m   {"id":"msg_1da52680826ee6cbd326c873","type":"message","role":"assistant","model":"qwen2.5:0.5b","content":[{"type":"text","text":"Your name is Alice"}],"stop_reason":"end_turn","usage":{"input_tokens":50,"output_tokens":5}}
[0;34m[INFO][0m Elapsed time: 813469000000ms
[1;33mâŠ˜ SKIP[0m POST /v1/messages (multi-turn) - endpoint not available
  [0;34mTo enable:[0m Upgrade to Ollama 0.5.0+
[0;34m[Test 17/26][0m Testing POST /v1/messages (streaming with usage)...
[0;34m[INFO][0m Request: POST http://localhost:11434/v1/messages (streaming with usage)
[0;34m[INFO][0m Response (all events):
[0;34m[INFO][0m   event: message_start
[0;34m[INFO][0m   data: {"type":"message_start","message":{"id":"msg_dc867a0823dc949fb65b526c","type":"message","role":"assistant","model":"qwen2.5:0.5b","content":[],"usage":{"input_tokens":1,"output_tokens":0}}}
[0;34m[INFO][0m   event: content_block_start
[0;34m[INFO][0m   data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Hello"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"!"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" It"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"'s"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" great"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" to"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" meet"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" you"}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"."}}
[0;34m[INFO][0m   event: content_block_delta
[0;34m[INFO][0m   data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" How"}}
[0;34m[INFO][0m   event: content_block_stop
[0;34m[INFO][0m   data: {"type":"content_block_stop","index":0}
[0;34m[INFO][0m   event: message_delta
[0;34m[INFO][0m   data: {"type":"message_delta","delta":{"stop_reason":"max_tokens"},"usage":{"input_tokens":30,"output_tokens":10}}
[0;34m[INFO][0m   event: message_stop
[0;34m[INFO][0m   data: {"type":"message_stop"}
[0;34m[INFO][0m Elapsed time: 1294981000000ms
[0;32mâœ“ PASS[0m POST /v1/messages (streaming with usage) includes usage data

=== Error Behavior Tests ===
[0;34m[Test 18/26][0m Testing error handling for nonexistent model...
[0;32mâœ“ PASS[0m Nonexistent model returns error status (404)
[0;34m[Test 19/26][0m Testing malformed request handling...
[0;32mâœ“ PASS[0m Malformed request returns error status (400)

=== Security Tests ===
[0;34m[Test 20/26][0m Verifying process owner (security check)...
[0;32mâœ“ PASS[0m Security: Ollama running as user (not root)
[0;34m[Test 21/26][0m Checking log files...
[0;32mâœ“ PASS[0m Log files exist and are readable (/tmp/ollama.stdout.log, /tmp/ollama.stderr.log)
[0;34m[Test 22/26][0m Checking plist file...
[0;32mâœ“ PASS[0m Plist file exists (/Users/vm/Library/LaunchAgents/com.ollama.plist)
[0;34m[Test 23/26][0m Checking OLLAMA_HOST in plist...
[0;32mâœ“ PASS[0m OLLAMA_HOST=0.0.0.0 configured in plist

=== Network Tests ===
[0;34m[Test 24/26][0m Checking service binding...
[0;32mâœ“ PASS[0m Service binds to all interfaces (0.0.0.0)
[0;34m[Test 25/26][0m Testing localhost access...
[0;32mâœ“ PASS[0m Localhost access (127.0.0.1) works
[0;34m[Test 26/26][0m Testing Tailscale IP access...
[0;32mâœ“ PASS[0m Tailscale IP access (100.91.192.8) works

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Test Summary                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[0;32mPassed:[0m  20
[0;31mFailed:[0m  2
[1;33mSkipped:[0m 4
Total:   26

[0;31mSome tests failed.[0m

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Next Steps                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â€¢ Check service status: launchctl list | grep ollama
  â€¢ Restart service: launchctl bootout gui/$(id -u)/com.ollama && launchctl bootstrap gui/$(id -u) ~/Library/LaunchAgents/com.ollama.plist
  â€¢ Check logs: tail -f /tmp/ollama.stderr.log
  â€¢ Verify port 11434: lsof -i :11434
  â€¢ Check Tailscale connectivity: tailscale status

